# ============================================
# Zara Voice Service Environment Configuration
# ============================================

# --- Azure OpenAI Voice Live (Required) ---
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
AZURE_OPENAI_API_KEY="your-azure-openai-key"
AZURE_OPENAI_DEPLOYMENT="gpt-4o-realtime"
AZURE_OPENAI_REALTIME_HOST="https://your-region.realtimeapi-preview.ai.azure.com"

# Optional Azure OpenAI overrides
AZURE_OPENAI_VOICE="alloy"
AZURE_OPENAI_SAMPLE_RATE="24000"
AZURE_OPENAI_API_VERSION="2025-08-28"


# --- Azure VoiceLive Bridge (Optional) ---
AZURE_VOICELIVE_ENDPOINT="https://your-voicelive-endpoint"
AZURE_VOICELIVE_MODEL="gpt-realtime"
AZURE_VOICELIVE_API_VERSION="2025-10-01"
# AZURE_VOICELIVE_API_KEY="your-voicelive-api-key"
# AZURE_VOICELIVE_VOICE="en-US-Ava:DragonHDLatestNeural"
# AZURE_VOICELIVE_INSTRUCTIONS="Custom instructions for VoiceLive sessions"


# --- Azure Speech Live Interpreter Translation (Optional) ---
# Set AZURE_SPEECH_SPEAKER_PROFILE_ID to enable Personal Voice output.
# When a speaker profile is configured the service will use the universal/v2 endpoint
# with the zero-shot TTS flight for low-latency synthesis automatically.
AZURE_SPEECH_TRANSLATION_KEY="your-speech-translation-key"
AZURE_SPEECH_TRANSLATION_REGION="eastus"
# AZURE_SPEECH_TRANSLATION_ENDPOINT="wss://<region>.stt.speech.microsoft.com/speech/universal/v2?setfeature=zeroshotttsflight"

# Target languages are ISO codes separated by commas (e.g. en,zh-Hans,ja).
AZURE_SPEECH_TRANSLATION_TARGET_LANGUAGES="en"
# Source language for translation (e.g. zh-CN, ja-JP, en-US)
# AZURE_SPEECH_TRANSLATION_SOURCE_LANGUAGE="zh-CN"
# For multiple source languages, use comma-separated list
# AZURE_SPEECH_TRANSLATION_SOURCE_LANGUAGES="zh-CN,ja-JP"
# Voice for synthesized translation output
# Set to "personal-voice" when using a Personal Voice speaker profile
# AZURE_SPEECH_TRANSLATION_VOICE="en-US-AvaMultilingualNeural"
# Optional override for the personal voice identifier (defaults to "personal-voice")
# AZURE_SPEECH_TRANSLATION_PERSONAL_VOICE_NAME="personal-voice"
# Enable/disable automatic source language detection
# AZURE_SPEECH_TRANSLATION_AUTO_DETECT="true"


# --- Azure Personal Voice Re-synthesis (Optional) ---
AZURE_SPEECH_KEY="your-speech-key"
AZURE_SPEECH_REGION="eastus"
AZURE_SPEECH_SPEAKER_PROFILE_ID="your-speaker-profile-id"
# AZURE_SPEECH_VOICE_NAME="DragonLatestNeural"
# AZURE_SPEECH_VOICE_STYLE="Prompt"
# AZURE_SPEECH_LANGUAGE="en-US"

# Set to "1" to enable manual SSML synthesis for translated audio
# AZURE_SPEECH_PERSONAL_VOICE_USE_SSML="1"
# Provide a custom SSML template (translated text is injected into {escaped_text})
# AZURE_SPEECH_PERSONAL_VOICE_SSML_TEMPLATE="<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xml:lang='{language}'><voice name='{voice_name}' parameters='cfg_scale=1.6;temperature=0.8;top_p=0.8;is_continue=False'><mstts:express-as style='neutral'><prosody rate='-10%' pitch='-2st'>{escaped_text}</prosody></mstts:express-as></voice></speak>"
# Or configure the helper to build SSML automatically:
# AZURE_SPEECH_PERSONAL_VOICE_SSML_RATE="-10%"
# AZURE_SPEECH_PERSONAL_VOICE_SSML_PITCH="-2st"
# AZURE_SPEECH_PERSONAL_VOICE_SSML_VOLUME="default"
# AZURE_SPEECH_PERSONAL_VOICE_SSML_STYLE="neutral"
# AZURE_SPEECH_PERSONAL_VOICE_SSML_ROLE="default"
# AZURE_SPEECH_PERSONAL_VOICE_SSML_OUTPUT_FORMAT="Riff24Khz16BitMonoPcm"


# --- WeatherAPI.com (Optional) ---
# WEATHER_API_KEY="your-weatherapi-key"
# WEATHER_API_BASE_URL="https://api.weatherapi.com/v1"
# WEATHER_API_TIMEOUT="10"
# WEATHER_API_LANG="en"
